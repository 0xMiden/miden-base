# Execution Model
Polygon Miden is a Rollup. We are batching state transitions - or more precisely proofs thereof - that happen in the same time period together into a block. 512 blocks together form an epoc of which the state root gets published to Ethereum. 

<p align="center">
  <img src="../diagrams/architecture/execution/Execution.png">
</p>

## Transaction Execution
Every Transaction will result in a ZK proof that attests its correctnes. But how do these ZK proofs get generated, and who generates them?

As mentioned in the previous notes, there are two types of transactions: (1) local transactions and (2) network transactions.

For local transactions, clients initiating the transactions also generate the proofs of their execution. So, no additional work needs to be performed by the network. Local transactions may be useful for two reasons:

1. They would enable privacy as neither the account state nor account code are needed to verify the ZKP.
2. They should be cheaper (i.e., lower fees) as ZKPs are already generated by the clients.

For network transactions, the block producer would generate the proofs. Network transactions may be useful for two reasons:

1. Clients may not have sufficient resources to generate ZK proofs (this may be especially relevant for mobile devices - at least for the near future).
2. Executing many transactions against the same public account by different clients would be challenging as the account state would change after every transaction. In this case, block producer can act as a "synchronizer" as they can execute transactions sequentially and feed the output of the previous transaction into the subsequent one.

In both cases, the entity generating a transaction proof would need to execute the same program on the VM (i.e., the program which executes a prologue, note scripts, epilogue etc. - as described in tx model note). We will call this program a **tx kernel**.

The Miden Node could also "outsource" tx proof generation to others as all proofs could be generated independently in parallel. Though, in cases when many transactions are executed against the same account, the block producer would also need to provided additional info (i.e., before/after account states) to such helpers (or another option could be to give all transactions which touch a particular account to the same helper).

Block producers will get compensated for the proof generation for network transactions. Thus, clients submitting network transactions would need to include a higher fee. The amount of the extra fee may be determined by the market, but more thinking is needed on how it can be made easy to estimate.


## Transaction Batching
Verifying a STARK proof within the VM should be relatively efficient (though, this has not been implemented it) - but it is still a pretty costly operation. I don't know what the actual numbers will come out to be, but I don't think it will be desirable to verify more than 100 proofs inside a single larger proof (at least for the near future).

However, if we are able to batch transactions, each batch could contain 100 transactions (or w/e the number that makes sense), and the block-level proof would contain 100 batch proofs. This way, each block could fit 10K transactions, which will be processed in batches of 100 in parallel.

To generate transaction batches we will also need to have a separate program. We will call this program ag kernel.

We can also take the batching approach a step further and add more recursion layers (i.e., batches of batches) - but this will complicate both the ag kernel and the os kernel quite a bit. So, my thinking is that at least initially, we don't try to do that.

Another interesting benefit of batching is that we may be able to use it to support proof generation on resource-constraint devices. One of the reasons why proof generation for transactions will be expensive is that to do recursive proof aggregation we need to build lower-level proofs using arithmetization-friendly hash functions (i.e., Rescue Prime in our case). These hash functions are not very efficient (i.e., probably 30x less efficient than BLAKE3) and will dominate proof generation costs.

However, with batching, we can allow the following:

1. Clients generate their tx proofs using BLAKE3 or SHA256 hash functions - which should be significantly faster than using Rescue Prime or similar.
2. Batch producer verifies these proofs and outputs a batch proof which uses Rescue Prime as the hash function.
3. Block producer aggregates batches as before. The fact that some tx proofs were built using non-arithmetization-friendly hashes is transparent to them.

Recursively verifying proofs built using BLAKE3/SHA256 would be quite a bit more expensive - so, such transactions would need to include higher fee - but there could be use cases where this may be justified.

## State progress 
For simplicity, let's imagine a simple centralized model:
* The Miden Node collects transactions from users.
* The Miden Node puts collected transactions into blocks.
* The blocks get submitted to Ethereum L1, and once a block is included in the L1 chain, the rollup chain is assumed to have moved to the next state.

A block which the Miden Node produces looks like this:

<p align="center">
  <img src="../diagrams/architecture/execution/Block.png">
</p>

A few notes about the above:

* **state updates** contain only the hashes of changes. For example, for each account which was updated, we'd record a tuple `([account id], [new account hash])`.
* The included **zk proof** attests that given a state commitment from the previous block, there was a sequence of valid transactions executed that resulted in the new state commitment, and also output included state updates.
* The block also contains full account and note data for public accounts and notes. For example, if account `123` is a public account which was updated, in the *state updates* section we'd have a records for it as `(123, 0x456..)`. The full new state of this account (which should hash to `0x456..`) would be included in a separate section.

Then, to verify that this block describes a valid transition, we'd do the following:
1. Compute hashes of public account and note states.
2. Make sure these hashes match records in the *state updates* section.
3. Verify the included ZKP against the following public inputs:
   - State commitment from the previous block.
   - State commitment from the current block.
   - State updates from the current block.

The above can be performed by an L1 contract for a full rollup mode. Or, if we skip the first two steps and put only state updates (without full account/note state) on L1, this would be something in between a rollup and validium.

This structure has another nice property: it is very easy for a new node to sync up to the current state from genesis. The new node would need to do the following:
1. Download only the first parts of the blocks (i.e., without full account/note states) starting at the genesis up until the latest block.
2. Verify all ZKPs in the downloaded blocks. This will be super quick (exponentially faster than re-executing original transactions) and can also be done in parallel.
3. Download the current states of account, note, and nullifier databases.
4. Verify that the downloaded current state matches the state commitment in the latest block.

Overall, state sync would be dominated by the time needed to download the data. There are ways to dramatically optimize this part as well (e.g., recursive state proofs) - but I'll leave these for another note.
